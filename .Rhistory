library(quanteda)
library(quanteda.textstats)
library(dplyr)
library(tidyverse)
library(irr)
library(gridExtra)
library(grid)
library(tikzDevice)
library("readxl")
library(rstudioapi)
# Set working directory to source file location
setwd(dirname(getActiveDocumentContext()$path))
getwd()
#clear working directory
rm(list = ls())
#load coded dataset
hand_coding<-read.csv("hand_coding_sample_70_202310.csv",stringsAsFactors = F,encoding="UTF-8", sep=";")
hand_coding<-hand_coding[ -1,]
hand_coding$coder[hand_coding$coder=="beide -Rebecca"]<-"beide - Rebecca"
#filter into comparison datset of konstantin and rebecca dataset
hand_coding_both<-hand_coding%>%filter(coder%in%c("beide - Konstantin","beide - Rebecca"))
hand_coding_kon<-hand_coding%>%filter(coder=="beide - Konstantin" )
hand_coding_reb<-hand_coding%>%filter(coder=="beide - Rebecca" )
dat1<-hand_coding_kon%>%select(sentence_id,sentence,a1_behavior,coder)
dat2<-hand_coding_reb%>%select(sentence_id,sentence,a1_behavior,coder)
names(dat2)[names(dat2)=="a1_behavior"] <- "a1_behavior_reb"
dat_all<-cbind(dat1,dat2)
dat_all$a1_behavior[dat_all$a1_behavior==4]<-0
dat_all$a1_behavior_reb[dat_all$a1_behavior_reb==4]<-0
dat_all$a1_behavior[dat_all$a1_behavior==3]<-1
dat_all$a1_behavior_reb[dat_all$a1_behavior_reb==3]<-1
dat_all$a1_behavior[dat_all$a1_behavior==2]<-1
dat_all$a1_behavior_reb[dat_all$a1_behavior_reb==2]<-1
#dataset, all the same coding for a1_behavior (explanans coding)
dat_all_same<-subset(dat_all,a1_behavior==a1_behavior_reb)
#dataset, not the same coding for a1_behaviour (explanans coding)
dat_all_not_same<-subset(dat_all,a1_behavior!=a1_behavior_reb)
write.csv(dat_all_not_same, 'dat_all_not_same_2.csv', row.names = FALSE,fileEncoding = "UTF-8")
library(quanteda)
library(quanteda.textstats)
library(dplyr)
library(tidyverse)
library(irr)
library(gridExtra)
library(grid)
library(tikzDevice)
library("readxl")
library(rstudioapi)
# Set working directory to source file location
setwd(dirname(getActiveDocumentContext()$path))
getwd()
#clear working directory
rm(list = ls())
#load dataset
load("data/covtext_press_releases.RData")
#remove white space
require(stringr)
example(str_trim)
covtext_press_releases$text<-str_squish(covtext_press_releases$text)
covtext_press_releases$headline<-str_squish(covtext_press_releases$headline)
#replace Mio., Mrd. and Nr.
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Mrd.","Milliarden")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Mio.","Millionen")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Nr.","Nummer")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Dr.","Dr")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Prof.","Prof")
#replace . by dates in text
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Januar"," Januar")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Febraur"," Februar")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". M?rz"," M?rz")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". April"," April")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Mai"," Mai")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Juni"," Juni")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Juli"," Juli")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". August"," August")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". September"," September")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Oktober"," Oktober")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". November"," November")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Dezember"," Dezember")
#creating corpus
corpus_press_releases<- corpus(covtext_press_releases$text)
#applying dictionary to corpus
dfmat_press_vac <- tokens_tolower(tokens(corpus_press_releases)) %>%
tokens_lookup(dictionary = dict_vaccination) %>%
dfm()
#create dictionary to filter for vaccination strategy press releases
dict_vaccination <- dictionary(list(vaccination = c("impf*")))
dfmat_press_vac <- tokens_tolower(tokens(corpus_press_releases)) %>%
tokens_lookup(dictionary = dict_vaccination) %>%
dfm()
#convert dictionary results back to data frame
df_press_dict<-convert(dfmat_press_vac, "data.frame")
press_releases_dict<-cbind(covtext_press_releases,df_press_dict)
#only press releases that have lockdown related words in their headline
press_releases_vaccination<-press_releases_dict%>%filter(vaccination>0)
#min date
min(press_releases_vaccination$date)
#max date
max(press_releases_vaccination$date)
#removing one press release because only overview page
press_releases_vaccination<-press_releases_vaccination[!press_releases_vaccination$date=="2020-01-01",]
#group lockdown press releases by date
vaccination_date<-press_releases_vaccination%>% group_by(date)%>%
summarise(vaccination = n())
vaccination_date$date[vaccination_date$vaccination==max(vaccination_date$vaccination)]
#plot how often lockdown words occur in press
plot_vaccination_date<-ggplot(vaccination_date, aes(x=date, y=vaccination,group=1)) +
geom_line()+stat_smooth(method = "loess",
formula = y ~ x, se=F,  linewidth = 1)+
xlab("Date")+ylab("Word Count")+ggtitle("Frequency of Vaccination Related Words in Press Releases over Time")+
scale_x_discrete(breaks = c("2020-10-30","2021-03-01","2021-11-24","2022-02-10")) +
theme_minimal()+theme(legend.position="none")
plot_vaccination_date
pdf("plots/plot_vaccination.pdf")
plot_vaccination_date
dev.off()
library(quanteda)
library(quanteda.textstats)
library(dplyr)
library(tidyverse)
library(irr)
library(gridExtra)
library(grid)
library(tikzDevice)
library("readxl")
library(rstudioapi)
# Set working directory to source file location
setwd(dirname(getActiveDocumentContext()$path))
getwd()
#clear working directory
rm(list = ls())
#load dataset
load("data/covtext_press_releases.RData")
#remove white space
require(stringr)
example(str_trim)
covtext_press_releases$text<-str_squish(covtext_press_releases$text)
covtext_press_releases$headline<-str_squish(covtext_press_releases$headline)
#replace Mio., Mrd. and Nr.
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Mrd.","Milliarden")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Mio.","Millionen")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Nr.","Nummer")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Dr.","Dr")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Prof.","Prof")
#replace . by dates in text
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Januar"," Januar")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Febraur"," Februar")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". M?rz"," M?rz")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". April"," April")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Mai"," Mai")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Juni"," Juni")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Juli"," Juli")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". August"," August")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". September"," September")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Oktober"," Oktober")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". November"," November")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Dezember"," Dezember")
#-----------------------------------------------#
#            Lockdown Strategy
#-----------------------------------------------#
#create dictionary to filter for lockdown press releases
dict_lockdown <- dictionary(list(lockdown = c("*lockdown*", "ausgangssperre*","*massenquarant*")))
#create dictionary to filter for vaccination strategy press releases
dict_vaccination <- dictionary(list(vaccination = c("*impfstrategie*", "*impfangebot*","*verimpfung*")))
#creating corpus
corpus_press_releases<- corpus(covtext_press_releases$text)
#applying dictionary to corpus
dfmat_press_lock <- tokens_tolower(tokens(corpus_press_releases)) %>%
tokens_lookup(dictionary = dict_lockdown) %>%
dfm()
#convert dictionary results back to data frame
df_press_dict<-convert(dfmat_press_lock, "data.frame")
press_releases_dict<-cbind(covtext_press_releases,df_press_dict)
#only press releases that have lockdown related words in their headline
press_releases_lockdown<-press_releases_dict%>%filter(lockdown>0)
#min date
min(press_releases_lockdown$date)
#max date
max(press_releases_lockdown$date)
#adapting for press releases with wrong date
press_releases_lockdown$date[press_releases_lockdown$date=="2020-02-10"]<-"2021-02-10"
#removing one press release because only overview page
press_releases_lockdown<-press_releases_lockdown[!press_releases_lockdown$date=="2020-01-01",]
#group lockdown press releases by date
lockdown_date<-press_releases_lockdown%>% group_by(date)%>%
summarise(lockdown = n())
lockdown_date$date[lockdown_date$lockdown==max(lockdown_date$lockdown)]
#plot how often lockdown words occur in press
plot_lockdown_date<-ggplot(lockdown_date, aes(x=date, y=lockdown,group=1)) +
geom_line()+stat_smooth(aes(col = "300"),
method = "gam",
formula = y ~ s(x, k = 500),
se = FALSE, linewidth = 1)+
xlab("Date")+ylab("Word Count")+ggtitle("Frequency of Lockdown Related Words in Press Releases over Time")+
scale_x_discrete(breaks = c("2020-04-01","2020-10-30","2021-03-01","2021-09-01","2022-02-01")) +
theme_minimal()+theme(legend.position="none")
plot_lockdown_date
pdf("plots/plot_lockdown.pdf")
plot_lockdown_date
dev.off()
#-----------------------------------------------#
#            Vaccination Strategy
#-----------------------------------------------#
#create dictionary to filter for vaccination strategy press releases
dict_vaccination <- dictionary(list(vaccination = c("impf*", "verimpf*")))
#creating corpus
corpus_press_releases<- corpus(covtext_press_releases$text)
#applying dictionary to corpus
dfmat_press_vac <- tokens_tolower(tokens(corpus_press_releases)) %>%
tokens_lookup(dictionary = dict_vaccination) %>%
dfm()
#convert dictionary results back to data frame
df_press_dict<-convert(dfmat_press_vac, "data.frame")
press_releases_dict<-cbind(covtext_press_releases,df_press_dict)
#only press releases that have lockdown related words in their headline
press_releases_vaccination<-press_releases_dict%>%filter(vaccination>0)
#min date
min(press_releases_vaccination$date)
#max date
max(press_releases_vaccination$date)
#removing one press release because only overview page
press_releases_vaccination<-press_releases_vaccination[!press_releases_vaccination$date=="2020-01-01",]
#group lockdown press releases by date
vaccination_date<-press_releases_vaccination%>% group_by(date)%>%
summarise(vaccination = n())
vaccination_date$date[vaccination_date$vaccination==max(vaccination_date$vaccination)]
#plot how often lockdown words occur in press
plot_vaccination_date<-ggplot(vaccination_date, aes(x=date, y=vaccination,group=1)) +
geom_line()+stat_smooth(method = "loess",
formula = y ~ x, se=F,  linewidth = 1)+
xlab("Date")+ylab("Word Count")+ggtitle("Frequency of Vaccination Related Words in Press Releases over Time")+
scale_x_discrete(breaks = c("2020-10-30","2021-03-01","2021-11-24","2022-02-10")) +
theme_minimal()+theme(legend.position="none")
plot_vaccination_date
pdf("plots/plot_vaccination.pdf")
plot_vaccination_date
dev.off()
covid_corp_vac <- corpus(press_releases_vaccination$text)
covid_corp_vac_sentence <- corpus_reshape(covid_corp_vac, to = "sentences")
ndoc(covid_corp_vac_sentence)
#sentence corpus to dataframe
press_releases_covid_vac_sentence<-convert(covid_corp_vac_sentence, to = "data.frame")
#merge sentence data with whole dataset
names(press_releases_covid_vac_sentence)[names(press_releases_covid_vac_sentence) == 'doc_id'] <- 'sentence_id'
names(press_releases_covid_vac_sentence)[names(press_releases_covid_vac_sentence) == 'text'] <- 'sentence'
#create merging var
press_releases_vaccination$text_id <- 1:nrow(press_releases_vaccination)
press_releases_vaccination$text_id<-paste0("text_",press_releases_vaccination$text_id)
#merge sentence level to full dataset of covid press releases
press_releases_vac_sentences<-press_releases_vaccination%>% left_join(press_releases_covid_vac_sentence, by="text_id")
View(press_releases_vaccination)
View(press_releases_covid_vac_sentence)
#create merging var
press_releases_vaccination$text_id <- 1:nrow(press_releases_vaccination)
press_releases_vaccination$text_id<-paste0("text.",press_releases_vaccination$text_id)
#merge sentence level to full dataset of covid press releases
press_releases_vac_sentences<-press_releases_vaccination%>% left_join(press_releases_covid_vac_sentence, by="text_id")
press_releases_covid_vac_sentence$text_id<-str_extract(press_releases_covid_vac_sentence$sentence_id, ".*(?=\\.)")
press_releases_covid_vac_sentence$text_id<-str_remove(press_releases_covid_vac_sentence$text_id, "text")
press_releases_covid_vac_sentence$text_id<-paste0("text_",press_releases_covid_vac_sentence$text_id)
#merge sentence level to full dataset of covid press releases
press_releases_vac_sentences<-press_releases_vaccination%>% left_join(press_releases_covid_vac_sentence, by="text_id")
View(press_releases_vac_sentences)
covid_corp_vac <- corpus(press_releases_vaccination$text)
covid_corp_vac_sentence <- corpus_reshape(covid_corp_vac, to = "sentences")
ndoc(covid_corp_vac_sentence)
#sentence corpus to dataframe
press_releases_covid_vac_sentence<-convert(covid_corp_vac_sentence, to = "data.frame")
#merge sentence data with whole dataset
names(press_releases_covid_vac_sentence)[names(press_releases_covid_vac_sentence) == 'doc_id'] <- 'sentence_id'
names(press_releases_covid_vac_sentence)[names(press_releases_covid_vac_sentence) == 'text'] <- 'sentence'
press_releases_covid_vac_sentence$text_id<-str_extract(press_releases_covid_vac_sentence$sentence_id, ".*(?=\\.)")
press_releases_covid_vac_sentence$text_id<-str_remove(press_releases_covid_vac_sentence$text_id, "text")
press_releases_covid_vac_sentence$text_id<-paste0("text_",press_releases_covid_vac_sentence$text_id)
#create merging var
press_releases_vaccination$text_id <- 1:nrow(press_releases_vaccination)
press_releases_vaccination$text_id<-paste0("text_",press_releases_vaccination$text_id)
#merge sentence level to full dataset of covid press releases
press_releases_vac_sentences<-press_releases_vaccination%>% left_join(press_releases_covid_vac_sentence, by="text_id")
View(press_releases_vac_sentences)
save(press_releases_vac_sentences, file="data/press_releases_vac_sentences.Rdata")
#create random sample, n=50
set.seed(12345)
hand_coding_sample_30_vac <- press_releases_vac_sentences %>% distinct(text_id) %>%
sample_n(30, replace = FALSE)  %>% inner_join(press_releases_vac_sentences, .)
unique(press_releases_vac_sentences$text_id)
#save random sample
write.csv(hand_coding_sample_30_vac, 'data/hand_coding_sample_30_vac.csv', row.names = FALSE,fileEncoding = "UTF-8")
rm(list = ls())
#load dataset
load("data/covtext_press_releases.RData")
#remove white space
require(stringr)
example(str_trim)
covtext_press_releases$text<-str_squish(covtext_press_releases$text)
covtext_press_releases$headline<-str_squish(covtext_press_releases$headline)
#replace Mio., Mrd. and Nr.
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Mrd.","Milliarden")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Mio.","Millionen")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Nr.","Nummer")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Dr.","Dr")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, "Prof.","Prof")
#replace . by dates in text
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Januar"," Januar")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Febraur"," Februar")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". M?rz"," M?rz")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". April"," April")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Mai"," Mai")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Juni"," Juni")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Juli"," Juli")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". August"," August")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". September"," September")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Oktober"," Oktober")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". November"," November")
covtext_press_releases$text<-str_replace_all(covtext_press_releases$text, ". Dezember"," Dezember")
#-----------------------------------------------#
#            Lockdown Strategy
#-----------------------------------------------#
#create dictionary to filter for lockdown press releases
dict_lockdown <- dictionary(list(lockdown = c("*lockdown*", "ausgangssperre*","*massenquarant*")))
#create dictionary to filter for vaccination strategy press releases
dict_vaccination <- dictionary(list(vaccination = c("*impfstrategie*", "*impfangebot*","*verimpfung*")))
#creating corpus
corpus_press_releases<- corpus(covtext_press_releases$text)
#applying dictionary to corpus
dfmat_press_lock <- tokens_tolower(tokens(corpus_press_releases)) %>%
tokens_lookup(dictionary = dict_lockdown) %>%
dfm()
#convert dictionary results back to data frame
df_press_dict<-convert(dfmat_press_lock, "data.frame")
press_releases_dict<-cbind(covtext_press_releases,df_press_dict)
#only press releases that have lockdown related words in their headline
press_releases_lockdown<-press_releases_dict%>%filter(lockdown>0)
#min date
min(press_releases_lockdown$date)
#max date
max(press_releases_lockdown$date)
#adapting for press releases with wrong date
press_releases_lockdown$date[press_releases_lockdown$date=="2020-02-10"]<-"2021-02-10"
#removing one press release because only overview page
press_releases_lockdown<-press_releases_lockdown[!press_releases_lockdown$date=="2020-01-01",]
#group lockdown press releases by date
lockdown_date<-press_releases_lockdown%>% group_by(date)%>%
summarise(lockdown = n())
lockdown_date$date[lockdown_date$lockdown==max(lockdown_date$lockdown)]
#plot how often lockdown words occur in press
plot_lockdown_date<-ggplot(lockdown_date, aes(x=date, y=lockdown,group=1)) +
geom_line()+stat_smooth(aes(col = "300"),
method = "gam",
formula = y ~ s(x, k = 500),
se = FALSE, linewidth = 1)+
xlab("Date")+ylab("Word Count")+ggtitle("Frequency of Lockdown Related Words in Press Releases over Time")+
scale_x_discrete(breaks = c("2020-04-01","2020-10-30","2021-03-01","2021-09-01","2022-02-01")) +
theme_minimal()+theme(legend.position="none")
plot_lockdown_date
pdf("plots/plot_lockdown.pdf")
plot_lockdown_date
dev.off()
#quanteda sentences
covid_corp_lock <- corpus(press_releases_lock$text)
covid_corp_lock <- corpus(press_releases_lockdown$text)
covid_corp_lock_sentence <- corpus_reshape(covid_corp_lock, to = "sentences")
ndoc(covid_corp_lock_sentence)
#sentence corpus to dataframe
press_releases_covid_lock_sentence<-convert(covid_corp_lock_sentence, to = "data.frame")
#merge sentence data with whole dataset
names(press_releases_covid_lock_sentence)[names(press_releases_covid_lock_sentence) == 'doc_id'] <- 'sentence_id'
names(press_releases_covid_lock_sentence)[names(press_releases_covid_lock_sentence) == 'text'] <- 'sentence'
press_releases_covid_lock_sentence$text_id<-str_extract(press_releases_covid_lock_sentence$sentence_id, ".*(?=\\.)")
press_releases_covid_lock_sentence$text_id<-str_remove(press_releases_covid_lock_sentence$text_id, "text")
press_releases_covid_lock_sentence$text_id<-paste0("text_",press_releases_covid_lock_sentence$text_id)
press_releases_lockdown$text_id <- 1:nrow(press_releases_lockdown)
press_releases_lockdown$text_id<-paste0("text_",press_releases_lockdown$text_id)
#merge sentence level to full dataset of covid press releases
press_releases_lockdown_sentences<-press_releases_lockdown%>% left_join(press_releases_covid_lock_sentence, by="text_id")
save(press_releases_lockdown_sentences, file="data/press_releases_lockdown_sentences.Rdata")
#create random sample, n=50
set.seed(12345)
hand_coding_sample_30_lock <- press_releases_lockdown_sentences %>% distinct(text_id) %>%
sample_n(30, replace = FALSE)  %>% inner_join(press_releases_lockdown_sentences, .)
unique(press_releases_lockdown_sentences$text_id)
#save random sample
write.csv(hand_coding_sample_30_lock, 'data/hand_coding_sample_30_lock.csv', row.names = FALSE,fileEncoding = "UTF-8")
View(hand_coding_sample_30_lock)
View(press_releases_dict)
#filter for date
press_releases_lockdown_sentences<-press_releases_lockdown_sentences%>%filter(date>="2020-11-02"&date<="2021-05-11")
hand_coding_sample_30_lock <- press_releases_lockdown_sentences %>% distinct(text_id) %>%
sample_n(30, replace = FALSE)  %>% inner_join(press_releases_lockdown_sentences, .)
View(press_releases_lockdown)
#merge sentence level to full dataset of covid press releases
press_releases_lockdown_sentences<-press_releases_lockdown%>% left_join(press_releases_covid_lock_sentence, by="text_id")
#merge sentence level to full dataset of covid press releases
press_releases_lockdown_sentences<-press_releases_lockdown%>% left_join(press_releases_covid_lock_sentence, by="text_id")
View(press_releases_lockdown_sentences)
#filter for date
press_releases_lockdown_sentences<-press_releases_lockdown_sentences%>%filter(date>="2020-11-02"&date<="2021-05-11")
#merge sentence level to full dataset of covid press releases
press_releases_lockdown_sentences<-press_releases_lockdown%>% left_join(press_releases_covid_lock_sentence, by="text_id")
#filter for date
press_releases_lockdown_sentences<-press_releases_lockdown_sentences%>%filter(date>="2020-11-02"&date<="2021-05-11")
View(press_releases_lockdown_sentences)
set.seed(12345)
hand_coding_sample_30_lock <- press_releases_lockdown_sentences %>% distinct(text_id) %>%
sample_n(30, replace = FALSE)  %>% inner_join(press_releases_lockdown_sentences, .)
unique(press_releases_lockdown_sentences$text_id)
#save random sample
write.csv(hand_coding_sample_30_lock, 'data/hand_coding_sample_30_lock.csv', row.names = FALSE,fileEncoding = "UTF-8")
#create dictionary to filter for vaccination strategy press releases
dict_vaccination <- dictionary(list(vaccination = c("impf*", "verimpf*")))
#creating corpus
corpus_press_releases<- corpus(covtext_press_releases$text)
#applying dictionary to corpus
dfmat_press_vac <- tokens_tolower(tokens(corpus_press_releases)) %>%
tokens_lookup(dictionary = dict_vaccination) %>%
dfm()
#convert dictionary results back to data frame
df_press_dict<-convert(dfmat_press_vac, "data.frame")
press_releases_dict<-cbind(covtext_press_releases,df_press_dict)
#only press releases that have lockdown related words in their headline
press_releases_vaccination<-press_releases_dict%>%filter(vaccination>0)
#min date
min(press_releases_vaccination$date)
#max date
max(press_releases_vaccination$date)
#removing one press release because only overview page
press_releases_vaccination<-press_releases_vaccination[!press_releases_vaccination$date=="2020-01-01",]
#group lockdown press releases by date
vaccination_date<-press_releases_vaccination%>% group_by(date)%>%
summarise(vaccination = n())
vaccination_date$date[vaccination_date$vaccination==max(vaccination_date$vaccination)]
#plot how often lockdown words occur in press
plot_vaccination_date<-ggplot(vaccination_date, aes(x=date, y=vaccination,group=1)) +
geom_line()+stat_smooth(method = "loess",
formula = y ~ x, se=F,  linewidth = 1)+
xlab("Date")+ylab("Word Count")+ggtitle("Frequency of Vaccination Related Words in Press Releases over Time")+
scale_x_discrete(breaks = c("2020-10-30","2021-03-01","2021-11-24","2022-02-10")) +
theme_minimal()+theme(legend.position="none")
plot_vaccination_date
pdf("plots/plot_vaccination.pdf")
plot_vaccination_date
dev.off()
#--------------------------------- SENTENCES VACINATION------------------------------#
#quanteda sentences
covid_corp_vac <- corpus(press_releases_vaccination$text)
covid_corp_vac_sentence <- corpus_reshape(covid_corp_vac, to = "sentences")
ndoc(covid_corp_vac_sentence)
#sentence corpus to dataframe
press_releases_covid_vac_sentence<-convert(covid_corp_vac_sentence, to = "data.frame")
#merge sentence data with whole dataset
names(press_releases_covid_vac_sentence)[names(press_releases_covid_vac_sentence) == 'doc_id'] <- 'sentence_id'
names(press_releases_covid_vac_sentence)[names(press_releases_covid_vac_sentence) == 'text'] <- 'sentence'
press_releases_covid_vac_sentence$text_id<-str_extract(press_releases_covid_vac_sentence$sentence_id, ".*(?=\\.)")
press_releases_covid_vac_sentence$text_id<-str_remove(press_releases_covid_vac_sentence$text_id, "text")
press_releases_covid_vac_sentence$text_id<-paste0("text_",press_releases_covid_vac_sentence$text_id)
#create merging var
press_releases_vaccination$text_id <- 1:nrow(press_releases_vaccination)
press_releases_vaccination$text_id<-paste0("text_",press_releases_vaccination$text_id)
#merge sentence level to full dataset of covid press releases
press_releases_vac_sentences<-press_releases_vaccination%>% left_join(press_releases_covid_vac_sentence, by="text_id")
save(press_releases_vac_sentences, file="data/press_releases_vac_sentences.Rdata")
#filter for date
press_releases_vac_sentences<-press_releases_vac_sentences%>%filter(date>="2020-12-27"&date<="2021-07-06")
#create random sample, n=50
set.seed(12345)
hand_coding_sample_30_vac <- press_releases_vac_sentences %>% distinct(text_id) %>%
sample_n(30, replace = FALSE)  %>% inner_join(press_releases_vac_sentences, .)
unique(press_releases_vac_sentences$text_id)
#save random sample
write.csv(hand_coding_sample_30_vac, 'data/hand_coding_sample_30_vac.csv', row.names = FALSE,fileEncoding = "UTF-8")
shiny::runApp('C:/Users/rkitt/Documents/PostDoc/year_1/ShinyApp')
